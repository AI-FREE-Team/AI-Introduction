{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJyIFimFTiwP"
      },
      "source": [
        "![人工智慧 - 自由團隊](https://raw.githubusercontent.com/chenkenanalytic/img/master/af/aifreeteam.png)\n",
        "\n",
        "\n",
        "<center>Welcome to the course《Python: from business analytics to Artificial Intelligence》by AI . FREE Team.</center>\n",
        "<br>\n",
        "<center>歡迎大家來到 AI . FREE Team 《Python 從商業分析到人工智慧》的 AI 基礎教學 - Lesson 02 Logistic Regression (3-02)。 </center>\n",
        "<br>\n",
        "\n",
        "<center>(Author: Chen Ken；Date of published: 2021//；AI . FREE Team Website: https://aifreeblog.herokuapp.com/)</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG2kAgokoYWF"
      },
      "source": [
        "# 羅吉斯回歸\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN6w7-92o7uY"
      },
      "source": [
        "在現代開發深度學習、機器學習，都能透過相關套件、框架來做開發，但在應用套件及開發框架的便利性下，往往開發者知其然不知其所以然，因此在入門深度學習領域的起點，我們建議學習者還是需要瞭解演算法的過程，因此本篇教學將帶大家手刻羅吉斯回歸。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmE19QDujVeU"
      },
      "source": [
        "## STEP 0. 使用矩陣運算套件 (numpy)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM0UCPzWjb_s"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdUpf2XjqfIe"
      },
      "source": [
        "## STEP 1. Sigmoid 函數"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbclhYFKrBoq"
      },
      "source": [
        "先 code 出 sigmoid 的機率函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIwkpsFJoA4G"
      },
      "source": [
        "def sigmoid(x):\n",
        "    p = 1 / (1 + np.exp(-x))\n",
        "    return p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfvquALnrJiu"
      },
      "source": [
        "## STEP 2. 初始化權重"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WnGzvvxrdzo"
      },
      "source": [
        "針對羅吉斯函數的權重進行初始化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAtEidCHrcSw"
      },
      "source": [
        "def initial_weight(column_num):\n",
        "  a = np.zeros(shape=(column_num,1))\n",
        "  b = 0\n",
        "  return a, b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w8JyChrse7C"
      },
      "source": [
        "## STEP 3. 運算與微分求解"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdH9gFd6seJF"
      },
      "source": [
        "def calculation(a, b, x, y):\n",
        "\n",
        "  # 找出資料筆數\n",
        "  num_sample = x.shape[0]\n",
        "\n",
        "  # 算出在原始權重下，參數 x 的機率分佈位置\n",
        "  p = sigmoid(np.dot(x, a) + b)\n",
        "\n",
        "  # 成本函數 - 計算現有權重計算出來的結果與真實答案的差距\n",
        "  cost = (- 1 / num_sample) * np.sum(y * np.log(p) + (1 - y) * (np.log(1 - p)))\n",
        "  cost = np.squeeze(cost)\n",
        "\n",
        "  # 計算出微分導數\n",
        "  da = (1 / num_sample) * np.dot(x.T, (p - y))\n",
        "  db = (1 / num_sample) * np.sum(p - y)\n",
        "\n",
        "  # 儲存微分資訊\n",
        "  diffs = {\"da\": da,\n",
        "           \"db\": db}\n",
        "\n",
        "  return diffs, cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "773H71-Jkqms"
      },
      "source": [
        "## STEP 4. 透過微分導數更新模型權重"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6OInPYH1eik"
      },
      "source": [
        "def updates(a, b, x, y, loops, learning_rate):\n",
        "\n",
        "  costs = []\n",
        "\n",
        "  # 透過迴圈更新模型權重\n",
        "  for i in range(loops):\n",
        "    diffs, cost = calculation(a, b, x, y)\n",
        "    da = diffs[\"da\"]\n",
        "    db = diffs[\"db\"]\n",
        "    a = a - learning_rate * da\n",
        "    b = b - learning_rate * db\n",
        "\n",
        "    # 每百次紀錄成本函數的數值\n",
        "    if i % 100 == 0:\n",
        "      costs.append(cost)\n",
        "      # print 出成本\n",
        "      print (\"第 {} 次訓練迴圈 - 計算成本值: {}\".format(i, cost))\n",
        "\n",
        "  params = {\"a\": a,\n",
        "            \"b\": b}\n",
        "  diffs = {\"dw\": da,\n",
        "           \"db\": db}\n",
        "\n",
        "  return params, diffs, costs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIWx_-GdrinQ"
      },
      "source": [
        "## STEP 5. 建立預測判斷函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb96-sso2c-Z"
      },
      "source": [
        "def predict(a, b, x):\n",
        "\n",
        "  num_sample = x.shape[0]\n",
        "\n",
        "  # 建立預測判斷的矩陣 (初始化皆為 0)\n",
        "  y_predict = np.zeros((num_sample, 1))\n",
        "\n",
        "  # 透過 sigmoid 計算機率分布\n",
        "  p = sigmoid(np.dot(x, a) + b)\n",
        "\n",
        "  # 當機率大於 0.5 即更新 y 為 1\n",
        "  for i in range(len(p)):\n",
        "    if p[i] > 0.5:\n",
        "      y_predict[i] = 1\n",
        "    else:\n",
        "      y_predict[i] = 0\n",
        "\n",
        "  return y_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVc0gsIowUhb"
      },
      "source": [
        "## STEP 6. 執行羅吉斯模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSUCFuh23yoS"
      },
      "source": [
        "def run_model(x, y, iterations=2000, learning_rate=0.5):\n",
        "\n",
        "  # 初始化模型權重\n",
        "  a, b = initial_weight(x.shape[1])\n",
        "\n",
        "  # 透過模型運算、微分導數更新模型權重與計算成本\n",
        "  params, diffs, costs = updates(a, b, x, y, iterations, learning_rate)\n",
        "\n",
        "  a = params[\"a\"]\n",
        "  b = params[\"b\"]\n",
        "\n",
        "  # 進行預測並檢視預測命中率\n",
        "  y_predict = predict(a, b, x)\n",
        "  print(\"模型判斷正確率為: {} %\".format(100-np.mean(np.abs(y_predict-y))*100))\n",
        "\n",
        "  return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Em8_FdRyaM6"
      },
      "source": [
        "## STEP 7. 運行與檢視"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmaiY9frygL4"
      },
      "source": [
        "### (1) 建立資料\n",
        "\n",
        "以 Lesson 1， and, or, xor 的資料集為例做學習判斷"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7rNBGCe4mG2"
      },
      "source": [
        "x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "\n",
        "y_and = np.array([[0],[0],[0],[1]])\n",
        "y_or = np.array([[0],[1],[1],[1]])\n",
        "y_xor = np.array([[1],[0],[0],[1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxiCjdTIy0IZ"
      },
      "source": [
        "### (2) 運行模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8puUEjtV6hFl"
      },
      "source": [
        "run_model(x, y_and, iterations = 2000, learning_rate = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GQ-pZAG82YG"
      },
      "source": [
        "run_model(x, y_or, iterations = 2000, learning_rate = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCKagVHpy5Nb"
      },
      "source": [
        "run_model(x, y_xor, iterations = 2000, learning_rate = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5fSUAV_NlGg"
      },
      "source": [
        "#結論與發現"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn07j2Xo0t08"
      },
      "source": [
        "透過有架構的邏輯去撰寫機器學習的羅吉斯回歸演算法，能夠更深入去理解演算法的理論，\n",
        "\n",
        "雖然從實驗結果，我們仍發現無法處理 xor 的資料集，但是對於 and , or 皆能夠達到 100% 判斷正確率，\n",
        "\n",
        "羅吉斯回歸演算法的理論，可視作類神經模型的基礎架構，接下來讓我們將繼續為深度學習揭密！"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 更深入的教學與專案實作\n",
        "\n",
        "如果你/妳對於深入開發 AI 技術的專案有興趣，想嘗試更多、更有趣、更扎實的實務AI技術專案，\n",
        "\n",
        "歡迎參考我們從0到1的AI技術課程：[《學習 AI 一把抓：點亮人工智慧技能樹》](https://hahow.in/cr/slashie-ai-free-team)！"
      ],
      "metadata": {
        "id": "6X4jsuSKEN7E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9KkN2cXhgCB"
      },
      "source": [
        "# 課程文件\n",
        "\n",
        "### AI Foundations 課程清單\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 00 Preface 課程前言</a>\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 01 MP model</a>\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 02 Logistic Regression</a> (We are here now! --本篇課程--)\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 03 Neural Network</a>\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 04 Deep Neural Network</a>\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 05 Convolution Neural Network</a>\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 06 Handwriting Traditional Chinese Characters Recognition</a>\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 07 Sentiment Analysis</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4fDiivP5ajm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}