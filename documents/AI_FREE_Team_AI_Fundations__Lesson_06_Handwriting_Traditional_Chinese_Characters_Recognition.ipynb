{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJyIFimFTiwP"
      },
      "source": [
        "![人工智慧 - 自由團隊](https://raw.githubusercontent.com/chenkenanalytic/img/master/af/aifreeteam.png)\n",
        "\n",
        "\n",
        "<center>Welcome to the course《Python: from business analytics to Artificial Intelligence》by AI . FREE Team.</center>\n",
        "<br>\n",
        "<center>歡迎大家來到 AI . FREE Team 《Python 從商業分析到人工智慧》的 AI 基礎教學 - Lesson 06 Handwriting Traditional Chinese Characters Recognition (3-06)。 </center>\n",
        "<br>\n",
        "\n",
        "<center>(Author: Chen Ken；Date of published: 2021//；AI . FREE Team Website: https://aifreeblog.herokuapp.com/)</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG2kAgokoYWF"
      },
      "source": [
        "# 繁體中文字集手寫辨識\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN6w7-92o7uY"
      },
      "source": [
        "經過貓狗辨識的實作過後，我們學會了貓狗圖片的二元分類，但在電腦視覺領域中，最常見的問題仍為多元分類(辨識3個類別以上)，\n",
        "\n",
        "本篇實作將帶領讀者認識繁體中文手寫字集的使用，並帶大家進行繁體中文字集手寫辨識。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmE19QDujVeU"
      },
      "source": [
        "## STEP 0. 認識繁體中文手寫資料集\n",
        "\n",
        "AI . FREE Team 開源繁體中文手寫資料集： https://github.com/AI-FREE-Team/Traditional-Chinese-Handwriting-Dataset\n",
        "\n",
        "本篇教學改作自「繁體中文手寫辨識」：https://github.com/AI-FREE-Team/Handwriting-Chinese-Characters-Recognition\n",
        "\n",
        "※ 建議花點時間閱讀文件說明，以利快速認識資料集組成與使用方式。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM0UCPzWjb_s"
      },
      "source": [
        "### 下載資料集\n",
        "!git clone https://github.com/AI-FREE-Team/Traditional-Chinese-Handwriting-Dataset.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8j0c-vtr-C7"
      },
      "source": [
        "### 導入資料處理相關套件\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "### 建立路徑\n",
        "OutputFolder = '/content/Handwritten_Data'\n",
        "if not os.path.exists(OutputFolder):\n",
        "  os.mkdir(OutputFolder)\n",
        "  print( f'建立資料夾： \"{OutputFolder}\" ' )\n",
        "\n",
        "### 設定檔案執行路徑\n",
        "os.chdir(OutputFolder)\n",
        "\n",
        "### 檢查路徑\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xJjAJSkXsmT"
      },
      "source": [
        "### 解壓縮資料集至指定路徑\n",
        "\n",
        "### 移動到資料及檔案位置\n",
        "os.chdir('/content/Traditional-Chinese-Handwriting-Dataset/data')\n",
        "\n",
        "### 找出資料集壓縮檔，並解壓縮\n",
        "for item in os.listdir():\n",
        "  if item.endswith('.zip'):\n",
        "    file_path = os.path.abspath(item)\n",
        "    zip_ref = zipfile.ZipFile(file_path).extractall(OutputFolder)\n",
        "\n",
        "    #### 找出檔案位置，並移動到指定資料夾\n",
        "    source_path = OutputFolder + '/cleaned_data(50_50)'\n",
        "    img_list = os.listdir(source_path)\n",
        "    for img in img_list:\n",
        "      shutil.move(source_path + '/' + img, OutputFolder)\n",
        "\n",
        "  ### 移除解壓縮時，產生的資料夾\n",
        "  shutil.rmtree(OutputFolder + '/cleaned_data(50_50)')\n",
        "  print(f'檔案：\" {file_path}  \"成功解壓縮！')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_3hI3bVawp-"
      },
      "source": [
        "請檢視左方 \"Handwritten_Data\" 資料夾中是否有手寫圖檔。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdUpf2XjqfIe"
      },
      "source": [
        "## STEP 1. 資料集基礎整理\n",
        "\n",
        "將圖片資料分類，並以 \"字\" 作為資料夾進行分類圖片。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIwkpsFJoA4G"
      },
      "source": [
        "### 找出全部正確的字集圖檔\n",
        "ImageList = os.listdir(OutputFolder)\n",
        "ImageList = [img for img in ImageList if len(img)>1]\n",
        "\n",
        "### 找到所有字的類別\n",
        "WordList = list(set([w.split('_')[0] for w in ImageList]))\n",
        "\n",
        "### 依照字的類別，建立對應資料夾\n",
        "for w in WordList:\n",
        "  try:\n",
        "    os.chdir(OutputFolder)\n",
        "    os.mkdir(w)\n",
        "    MoveList = [img for img in ImageList if w in img]\n",
        "\n",
        "  except:\n",
        "    os.chdir(OutputFolder)\n",
        "    MoveList = [ img for img in ImageList if w in img ]\n",
        "\n",
        "  ### 將對應字的圖檔，移至對應的資料夾\n",
        "  finally:\n",
        "    for img in MoveList:\n",
        "      old_path = OutputFolder + '/' + img\n",
        "      new_path = OutputFolder + '/' + w + '/' + img\n",
        "      shutil.move( old_path, new_path )\n",
        "\n",
        "print('繁體中文手寫資料集部署完成！')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GifyUBvc-Tc"
      },
      "source": [
        "### ★ 檢查資料集是否部署成功 ★\n",
        "\n",
        "正確訊息顯示：\n",
        "\n",
        "> 總共: 4803 個字(資料夾) / 總共: 250712個樣本\n",
        ">\n",
        "> 平均每個字有: 52.19904226525089 個樣本"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDT9j6I_dKWU"
      },
      "source": [
        "a=0\n",
        "b=0\n",
        "\n",
        "for item in os.listdir(OutputFolder):\n",
        "  a += 1\n",
        "  for i in os.listdir(OutputFolder + '/' + item):\n",
        "    b +=1\n",
        "\n",
        "print('總共: ' + str(a) + ' 個字(資料夾) / 總共: ' + str(b) + '個樣本')\n",
        "print('平均每個字有: ' + str(b/a) + ' 個樣本')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4IOspeZZnaf"
      },
      "source": [
        "## STEP 2. 上傳自製資料集 (做為測試用)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ucYoskLhwzI"
      },
      "source": [
        "### 移動到指定資料夾，建立測試資料夾\n",
        "os.chdir('/content')\n",
        "os.mkdir('Traditional_Chinese_Testing_Data')\n",
        "os.chdir('/content/Traditional_Chinese_Testing_Data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h10a_NmNaLnR"
      },
      "source": [
        "### 下載 AI . FREE Team 測試手寫資料集\n",
        "!git clone https://github.com/AI-FREE-Team/Handwriting-Chinese-Characters-Recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsEM1u_sl3p9"
      },
      "source": [
        "### ★ 自製繁中手寫測試集說明 ★\n",
        "\n",
        "利用小畫家自製繁體中文字   \n",
        "* 底圖大小: 50x50 像素   \n",
        "* 白底黑字    \n",
        "* 像素筆線條粗細: 1 像素   \n",
        "\n",
        "將用小畫家自製的繁中手寫文字，以 png 檔儲存，且放於以該字為名的子資料夾中，如下圖所示:   \n",
        "![自製繁中手寫資料集](https://raw.githubusercontent.com/AI-FREE-Team/Traditional-Chinese-Handwriting-Dataset/master/img/HomeMade_Traditional_Chinese_Dataset.png)\n",
        "\n",
        "※ 讀者若有興趣替換為自己的手寫資料，可自己透過 colab 路徑設置，上傳資料集。\n",
        "\n",
        "※ 本篇教學，以「人」、「工」、「智」、「慧」作為訓練辨識目標。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdL1D3Nhl3p9"
      },
      "source": [
        "'''\n",
        "RawDataPath: 繁中手寫資料集路徑\n",
        "TraningDataPath: 訓練集路徑\n",
        "TestingDataPath: 自製繁中手寫資料集路徑\n",
        "'''\n",
        "RawDataPath = '/content/Handwritten_Data'\n",
        "TraningDataPath = '/content/Traditional_Chinese_Testing_Data/Handwriting-Chinese-Characters-Recognition/train data'\n",
        "TestingDataPath = '/content/Traditional_Chinese_Testing_Data/Handwriting-Chinese-Characters-Recognition/test data'\n",
        "\n",
        "os.chdir(RawDataPath)\n",
        "print('目前路徑', os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFH81c1VStyy"
      },
      "source": [
        "## STEP 3. 訓練字集設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf5DtSoU_u9q"
      },
      "source": [
        "### 選取人工智慧四個字\n",
        "SelectedWords = [ '人', '工', '智', '慧' ]\n",
        "\n",
        "### 將字集資料，移至指定資料夾\n",
        "os.chdir( RawDataPath )\n",
        "try:\n",
        "  os.mkdir( TraningDataPath )\n",
        "except:\n",
        "  shutil.rmtree( TraningDataPath )\n",
        "  os.mkdir( TraningDataPath )\n",
        "finally:\n",
        "  nonexistence = []\n",
        "  for c in SelectedWords:\n",
        "    try:\n",
        "      shutil.copytree( RawDataPath+'/'+c, TraningDataPath+'/'+c )\n",
        "    except:\n",
        "      nonexistence.append( c )\n",
        "\n",
        "  if len(nonexistence)>1:\n",
        "    print( f'There are {len(nonexistence)} characters that are not in dataset. \\n{nonexistence}' )\n",
        "  elif len(nonexistence)==1:\n",
        "    print( f'There is {len(nonexistence)} character that is not in dataset. \\n{nonexistence}' )\n",
        "  else:\n",
        "    None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xRVvNmbAcPn"
      },
      "source": [
        "## STEP 4. 引入繁中相關圖表顯示工具"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8OHMVZLhhse"
      },
      "source": [
        "from platform import python_version\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL.Image\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.font_manager import findfont, FontProperties\n",
        "'''\n",
        "繁體中文顯示設定\n",
        "'''\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "default_type = findfont( FontProperties( family=FontProperties().get_family() ) )\n",
        "ttf_path = '/'.join( default_type.split('/')[:-1] )  # 預設字型的資料夾路徑\n",
        "\n",
        "os.chdir( '/content' )\n",
        "if not os.path.exists( '/content/matplotlib_Display_Chinese_in_Colab' ):\n",
        "    !git clone https://github.com/YenLinWu/matplotlib_Display_Chinese_in_Colab\n",
        "\n",
        "os.chdir( '/content/matplotlib_Display_Chinese_in_Colab' )\n",
        "for item in os.listdir():\n",
        "    if item.endswith( '.ttf' ):\n",
        "        msj_ttf_path = os.path.abspath( item )\n",
        "        msj_name = msj_ttf_path.split('/')[-1]\n",
        "\n",
        "try:\n",
        "    shutil.move( msj_ttf_path, ttf_path )\n",
        "except:\n",
        "    pass\n",
        "finally:\n",
        "    os.chdir( '/content' )\n",
        "    shutil.rmtree( '/content/matplotlib_Display_Chinese_in_Colab' )\n",
        "font = FontProperties( fname=ttf_path+'/'+msj_name )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knlYmn9chYRw"
      },
      "source": [
        "## STEP 5. 檢視資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiT_rYDoB7dp"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "def Loading_Image(image_path):\n",
        "  img = load_img(image_path)\n",
        "  img = tf.constant(np.array(img))\n",
        "  return img\n",
        "\n",
        "def Show(image, title=None) :\n",
        "  if len(image.shape)>3 :\n",
        "    image = tf.squeeze(image, axis=0)\n",
        "\n",
        "  plt.imshow(image)\n",
        "  if title:\n",
        "    plt.title(title, fontproperties=font)\n",
        "\n",
        "img_list = []\n",
        "for c in SelectedWords :\n",
        "  folder_path = TraningDataPath+'/'+c\n",
        "  file_names = os.listdir(folder_path)\n",
        "  for i in range(5) :\n",
        "    img_list.append(folder_path+'/'+file_names[i])\n",
        "\n",
        "plt.gcf().set_size_inches((12,12))\n",
        "for i in range(20):\n",
        "  plt.subplot(4,5,i+1)\n",
        "  title = img_list[i].split('/')[-1].split('_')[-2]\n",
        "  img = Loading_Image( img_list[i] )\n",
        "  Show( img, title )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUSUVzqwB9nZ"
      },
      "source": [
        "## STEP 6. (超)參數設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVf2HXixiOP9"
      },
      "source": [
        "Num_Classes = len(SelectedWords)\n",
        "Image_Size = (50, 50)\n",
        "Epochs = 50\n",
        "Batch_Size = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93sGsZlXiGX_"
      },
      "source": [
        "## STEP 7. 資料擴增 Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoY1rzeqCk5p"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import *\n",
        "\n",
        "\n",
        "# 透過資料擴增，增加訓練及驗證的資料集\n",
        "Train_Data_Genetor = ImageDataGenerator(rescale = 1./255, validation_split = 0.2,\n",
        "                                        width_shift_range = 0.05,\n",
        "                                        height_shift_range = 0.05,\n",
        "                                        zoom_range = 0.1,\n",
        "                                        horizontal_flip = False)\n",
        "\n",
        "Train_Generator = Train_Data_Genetor.flow_from_directory(TraningDataPath ,\n",
        "                                                         target_size = Image_Size,\n",
        "                                                         batch_size = Batch_Size,\n",
        "                                                         class_mode = 'categorical',\n",
        "                                                         shuffle = True,\n",
        "                                                         subset = 'training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvz7pPy5iuJI"
      },
      "source": [
        "### ★ 檢視訓練資料集 ★"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WB7-etAiwfP"
      },
      "source": [
        "def Plot_Genetor( imgs, labels=[], grid=(1,10), size=(20,2) ):\n",
        "    n = len( imgs )\n",
        "    plt.gcf().set_size_inches(size)\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot( grid[0], grid[1], i+1 )\n",
        "        ax.imshow( imgs[i] )\n",
        "        if len(labels):\n",
        "            ax.set_title( f'Label={labels[i]}' )\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "    plt.show()\n",
        "\n",
        "batch = 1\n",
        "for data, label in Train_Generator:\n",
        "    print( f'batch {batch}: \\n shape of images: {data.shape} \\n shape of labels: {label.shape}' )\n",
        "    Plot_Genetor( data, label )\n",
        "    batch += 1\n",
        "    if batch > len(Train_Generator):\n",
        "        break\n",
        "\n",
        "print( f'There are {len(Train_Generator)} batches.' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kkOlJqhjMSw"
      },
      "source": [
        "### 測試集製作\n",
        "Val_Data_Genetor = ImageDataGenerator(rescale=1./255, validation_split = 0.2)\n",
        "Val_Generator = Train_Data_Genetor.flow_from_directory(TraningDataPath ,\n",
        "                                                       target_size = Image_Size,\n",
        "                                                       batch_size = Batch_Size,\n",
        "                                                       class_mode = 'categorical',\n",
        "                                                       shuffle = True,\n",
        "                                                       subset = 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UZOaSixDSSx"
      },
      "source": [
        "## STEP 8. 建構卷積神經模型\n",
        "\n",
        "使用 keras 建構卷積神經模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMgSpCy_Ss8b"
      },
      "source": [
        "### 定義 sequential 模型，使開發者可透過一層一層地堆疊模型層數\n",
        "CNN = Sequential(name = 'CNN_Model' )\n",
        "\n",
        "### 建立卷積層及池化層\n",
        "CNN.add(Conv2D(5, kernel_size = (2,2), padding = 'same',\n",
        "               input_shape = (Image_Size[0],Image_Size[1],3), name = 'Convolution'))\n",
        "CNN.add(MaxPooling2D(pool_size = (2,2), name = 'Pooling'))\n",
        "\n",
        "### 轉成全連接層\n",
        "CNN.add(Flatten(name = 'Flatten' ) )\n",
        "\n",
        "### 使用 dropout 避免 overfitting\n",
        "CNN.add(Dropout(0.5, name = 'Dropout_1' ) )\n",
        "\n",
        "### 第一層神經網絡 (512) 個神經元\n",
        "CNN.add(Dense(512, activation = 'relu', name = 'Dense'))\n",
        "\n",
        "### 使用 dropout 避免 overfitting\n",
        "CNN.add(Dropout(0.5, name = 'Dropout_2' ) )\n",
        "\n",
        "### 4 個神經元 → 因為將預測 4 個中文字的機率 (Num_Classes = 4)\n",
        "CNN.add(Dense(Num_Classes, activation = 'softmax', name = 'Softmax'))\n",
        "\n",
        "### 檢視模型的架構\n",
        "CNN.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbrNYvAmFYTZ"
      },
      "source": [
        "## STEP 9. 設定優化器與開始訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfdEZGO4Fi1H"
      },
      "source": [
        "### 使用 Adam 優化器；損失函數使用分類交叉熵\n",
        "CNN.compile(optimizer = Adam(),\n",
        "            loss = 'categorical_crossentropy',\n",
        "            metrics = ['accuracy'])\n",
        "\n",
        "### 開始訓練\n",
        "History = CNN.fit(Train_Generator,\n",
        "                  steps_per_epoch = Train_Generator.samples//Batch_Size,\n",
        "                  validation_data = Val_Generator,\n",
        "                  validation_steps = Val_Generator.samples//Batch_Size,\n",
        "                  epochs = Epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSLc0Rh3ku6J"
      },
      "source": [
        "### ★ 檢視訓練成效 ★"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXnvvovEktLp"
      },
      "source": [
        "Train_Accuracy = History.history['accuracy']\n",
        "Val_Accuracy = History.history['val_accuracy']\n",
        "Train_Loss = History.history['loss']\n",
        "Val_Loss = History.history['val_loss']\n",
        "epochs_range = range(Epochs)\n",
        "\n",
        "plt.figure( figsize=(14,4) )\n",
        "plt.subplot( 1,2,1 )\n",
        "plt.plot( range( len(Train_Accuracy) ), Train_Accuracy, label='Train' )\n",
        "plt.plot( range( len(Val_Accuracy) ), Val_Accuracy, label='Validation' )\n",
        "plt.legend( loc='lower right' )\n",
        "plt.title( 'Accuracy' )\n",
        "\n",
        "plt.subplot( 1,2,2 )\n",
        "plt.plot( range( len(Train_Loss) ), Train_Loss, label='Train' )\n",
        "plt.plot( range( len(Val_Loss) ), Val_Loss, label='Validation' )\n",
        "plt.legend( loc='upper right' )\n",
        "plt.title( 'Loss')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_zZYa_9GIHu"
      },
      "source": [
        "## STEP 10. 模型驗證與辨識\n",
        "\n",
        "建立 test 資料夾，將測試圖片做驗證。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uMnGb8p3kEI"
      },
      "source": [
        "### 建立測試資料夾\n",
        "os.mkdir('test')\n",
        "\n",
        "for i in os.listdir(TestingDataPath):\n",
        "  folder = TestingDataPath + '/' + i\n",
        "  for f in os.listdir(folder):\n",
        "    img_file = folder + '/' + f\n",
        "    shutil.copyfile(img_file,'/content/test/' + f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWSwuCublgKF"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing import image\n",
        "\n",
        "directory = os.fsencode('/content/test')\n",
        "\n",
        "def pred_to_chinese(pred):\n",
        "  if pred.round(1)[0][0] == 1:\n",
        "    ans = \"人\"\n",
        "  if pred.round(1)[0][1] == 1:\n",
        "    ans = \"工\"\n",
        "  if pred.round(1)[0][2] == 1:\n",
        "    ans = \"慧\"\n",
        "  if pred.round(1)[0][3] == 1:\n",
        "    ans = \"智\"\n",
        "  return ans\n",
        "\n",
        "\n",
        "# 辨識全部測試圖片\n",
        "for f in os.listdir(directory):\n",
        "  f = os.fsdecode(f)\n",
        "  img = image.load_img('/content/test/'+ str(f), target_size=(50, 50))\n",
        "\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis = 0)\n",
        "  pred = CNN.predict(x)\n",
        "\n",
        "  print('檔案名稱：',f)\n",
        "\n",
        "  ax = plt.subplot( )\n",
        "  ax.imshow(img)\n",
        "  ax.set_title( f'預測結果：{pred_to_chinese(pred)}', fontproperties=font)\n",
        "  ax.set_xticks([]); ax.set_yticks([])\n",
        "  plt.gcf().set_size_inches((20,2))\n",
        "  plt.show()\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5fSUAV_NlGg"
      },
      "source": [
        "#結論與發現"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn07j2Xo0t08"
      },
      "source": [
        "透過開發繁體中文手寫字集辨識，可以發現 AI 不僅能做二元分類，\n",
        "\n",
        "也能進行多元分類(辨識3個類別以上)，雖然訓練出來的 CNN 模型仍有可能辨識錯誤，\n",
        "\n",
        "但能夠解決多數圖像辨識等議題，甚至有許多衍生強化的模型有辦法達到更高精準度！\n",
        "\n",
        "既然人工智慧有辦法處理圖像的辨識與預測，若我們想透過對話使 AI 理解呢？\n",
        "\n",
        "下一篇教學，我們將帶領讀者走入自然語言專題：影評預測分析。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 更深入的教學與專案實作\n",
        "\n",
        "如果你/妳對於深入開發 AI 技術的專案有興趣，想嘗試更多、更有趣、更扎實的實務AI技術專案，\n",
        "\n",
        "歡迎參考我們從0到1的AI技術課程：[《學習 AI 一把抓：點亮人工智慧技能樹》](https://hahow.in/cr/slashie-ai-free-team)！"
      ],
      "metadata": {
        "id": "6X4jsuSKEN7E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9KkN2cXhgCB"
      },
      "source": [
        "# 課程文件\n",
        "\n",
        "### AI Foundations 課程清單\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 00 Preface 課程前言</a>\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 01 MP model</a>\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 02 Logistic Regression</a>\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 03 Neural Network</a>\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 04 Deep Neural Network</a>\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 05 Convolution Neural Network</a>\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 06 Handwriting Traditional Chinese Characters Recognition</a> (We are here now! --本篇課程--)\n",
        "- <a href=\"https://colab.research.google.com/github/AI-FREE-Team/Python-Basics/blob/master/documents/Lesson00%20Preface.ipynb\">Lesson 07 Sentiment Analysis</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4fDiivP5ajm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}